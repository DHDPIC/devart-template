This feels like an ideal opportunity to explore some of the exciting technology we have been itching to play with and find a focused project for.

![First Sketch](../project_images/IMG_1515_w.jpg?raw=true "First Sketch")

Smart mobile devices are something almost all of us who visit exhibitions possess, so make an incredibly powerful tool to interact with an exhibition installation. Using device orientation and motion capabilities in Chrome for Android allows for very simple interaction between a user and their device and an installation. It also means that the user doesn't have to look at their screen to interact so they are free to look at the. Of course other capabilities could be accessed too, deepening the interaction and enriching the experience. We are interested in allowing a user to navigate data and control a narrative, but also in feedback loops from their input.

The incredibly fast performance, 3D graphics, and shaders of WebGL should allow us to create some really exciting visual outcomes. Plus much easier to use thanks to three.js!

The main display and devices are connected together using the WebSockets API and node.js to send information from the device to the main display.

Our first experiments managed to set this connection up and allow a phone to control a sphere on the main display rendered in WebGL. You can see some images documenting this process below...


![Hello Devart](../project_images/IMG_1516_w.jpg?raw=true "Hello Devart")

![Orientation Sphere](../project_images/IMG_1517_w.jpg?raw=true "Orientation Sphere")
